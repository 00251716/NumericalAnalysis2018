{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimos cuadrados: caso discreto\n",
    "\n",
    "Dada una nube de puntos $ \\{ (x_{1}, y_{1}), (x_{2}, y_{2}), \\ldots , (x_{m}, y_{m})  \\} \\subseteq \\mathbb{R}^{2} $  deseamos buscar una función que provea una buena aproximación en cada uno de los $m$ puntos. Para poder abordar este problema, es necesario especificar a qué nos referimos con *buena aproximación*. \n",
    "Con este propósito, introducimos la noción de norma $2$ en $\\mathbb{R}^{m}$. Dado $\\mathbf{v} = ( v_{1}, \\ldots, v_{m} ) \\in \\mathbb{R}^{m}$, tenemos que\n",
    "\n",
    "$$ || \\mathbf{v} ||_{2} = \\left( \\sum_{i=1}^{m} (v_{i})^{2}  \\right) ^{ \\frac{1}{2} }   $$ \n",
    "\n",
    "Consideremos la nube de puntos como dos vectores m-dimensionales: $\\mathbf{x} = (x_{1}, x_{2}, \\ldots , x_{m}) \\in \\mathbb{R}^{m}$ y $\\mathbf{y} = (y_{1}, y_{2}, \\ldots , y_{m}) \\in \\mathbb{R}^{m} $ y supongamos que buscamos un polinomio $p_{n}$ de grado menor o igual que $n$ para aproximar la nube de puntos; es decir, deseamos minimizar la distancia entre cada $y_{i}$ en la nube de puntos y los valores de $p_{n}(x_{i})$. Si denotamos por $\\mathbf{p}$ el vector $m$-dimensional $( p_{n}(x_{1}), p_{n}(x_{2}), \\ldots , p_{n}(x_{m}) )$ tenemos que \n",
    "\n",
    "$$  || \\mathbf{y} - \\mathbf{p} ||_{2}   =  \\left( \\sum_{i=1}^{m} (y_{i} - p_{n}(x_{i}))^{2}  \\right) ^{ \\frac{1}{2} }  $$ \n",
    "\n",
    "Minimizar esta expresión es equivalente a minimizar\n",
    "\n",
    "$$  || \\mathbf{y} - \\mathbf{p} ||_{2}^{2}   =  \\sum_{i=1}^{m} (y_{i} - p_{n}(x_{i}))^{2}     $$\n",
    "\n",
    "Si escribimos $p_{n}(x)$ como $ \\sum_{i=0}^{n} a_{i} x^{i} $ notamos que esta expresión depende únicamente de los coeficientes del polinomio. De forma que si se desea obtener un mínimo, se debe asegurar la derivada parcial de esta expresión respecto a cada coeficiente $a_{i}$, $i = 0, 1, 2, \\ldots , n$ sea igual a $0$. Al realizar la derivación parcial e igualar a $0$, obtenemos el siguiente sistema de $n+1$ ecuaciones para los $n+1$ coeficientes:\n",
    "\n",
    "$$ \\begin{array}{rcr} a_{0}\\langle \\mathbf{1}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{1}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{1}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{1}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{1} \\rangle \\\\ \n",
    "a_{0}\\langle \\mathbf{x}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{x}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{x}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{x}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{x} \\rangle \\\\  \\vdots \\\\ \n",
    "a_{0}\\langle \\mathbf{x}^{n}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{x}^{n}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{x}^{n}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{x}^{n}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{x}^{n} \\rangle  \\end{array} $$\n",
    "\n",
    "donde denotamos por $\\mathbf{x} ^{i}$ el vector $(x_{1}^{i}, x_{2}^{i}, \\ldots , x_{m}^{i})$ y $\\langle \\mathbf{v}, \\mathbf{w} \\rangle = \\sum_{i=1}^{m} v_{i} w_{i}  $ es el producto interno en $\\mathbb{R} ^{m}$. Para el enfoque polinomial, resolvemos este sistema de ecuaciones para buscar los coeficientes.\n",
    "Si se sospecha que los datos tienen una relación exponencial, minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - a_{0} e^{a_{1} x_{i}})^{2}     $$\n",
    "\n",
    "linealizando la expresión como \n",
    "\n",
    "$$ \\sum_{i=1}^{m} (ln(y_{i}) - ( ln(a_{0}) + a_{1} x_{i} ))^{2}  $$\n",
    "\n",
    "Si sospechamos que los datos tienen una relación potencial, en su lugar minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - a_{0} x^{a_{1}})^{2} $$ \n",
    "\n",
    "linealizando como \n",
    "\n",
    "$$ \\sum_{i=1}^{m} (ln(y_{i}) - ( ln(a_{0}) + a_{1}ln( x_{i}) ))^{2}  $$\n",
    "\n",
    "Por último, si los datos tienen una relación logarítmica, minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - ( a_{0} + a_{1}ln( x_{i}) ))^{2}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x\n",
    "from mpmath import nsum\n",
    "\n",
    "from IPython.display import display, Latex\n",
    "from ipywidgets import interact, widgets, Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sympy.plotting import plot;\n",
    "import matplotlib.pyplot as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 8, 8\n",
    "\n",
    "from sympy.interactive import printing;\n",
    "printing.init_printing(use_latex=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de puntos a ingresar: 5\n"
     ]
    }
   ],
   "source": [
    "n = int(input('Cantidad de puntos a ingresar: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 4\n",
      "y0 = 102.56\n",
      "x1 = 4.2\n",
      "y1 = 113.18\n",
      "x2 = 4.5\n",
      "y2 = 130.11\n",
      "x3 = 4.7\n",
      "y3 = 142.05\n",
      "x4 = 5.1\n",
      "y4 = 167.53\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$ \\mathbf{x} = \\left [ 4.0, \\quad 4.2, \\quad 4.5, \\quad 4.7, \\quad 5.1\\right ]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$ \\mathbf{y} = \\left [ 102.56, \\quad 113.18, \\quad 130.11, \\quad 142.05, \\quad 167.53\\right ]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "puntos_x = []\n",
    "puntos_y = []\n",
    "for i in range(n):\n",
    "    puntos_x.append(float(input('x{:d} = '.format(i))))\n",
    "    puntos_y.append(float(input('y{:d} = '.format(i))))\n",
    "display(Latex('$$ \\mathbf{x} = '+latex(puntos_x)+'$$'))\n",
    "display(Latex('$$ \\mathbf{y} = '+latex(puntos_y)+'$$'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7493f0914d4ed08d4d14ff47d81b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Tipo de regresión: ', options={'Polinomial': 1, 'Exponencial': 2, 'Potencial': 3, 'Logar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case = 1\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options = {'Polinomial' : 1, 'Exponencial' : 2, 'Potencial' : 3, 'Logarítmica' : 4},\n",
    "    value = 1,\n",
    "    description = 'Tipo de regresión: '\n",
    ");\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grado del polinomio: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACW8AAAAVBAMAAADBH5NxAAAAMFBMVEX///8AAAAAAAAAAAAAAAAA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\nO7j//70u/wdvML7nppbjFQAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$- 1.24005118666392 \\cdot 10^{-6} x^{10} - 1.60231611732181 \\cdot 10^{-5} x^{9} + 0.000456720151187729 x^{8} - 0.00193528276314131 x^{7} - 0.00279317600199501 x^{6} - 0.00096923753055128 x^{5} + 0.141493891581525 x^{4} + 0.0432639792616021 x^{3} + 6.54012037706316 x^{2} - 12.1624406675846 x + 27.286578294022$$"
      ],
      "text/plain": [
       "                       10                        9                         8  \n",
       "- 1.24005118666392e-6⋅x   - 1.60231611732181e-5⋅x  + 0.000456720151187729⋅x  -\n",
       "\n",
       "                      7                        6                        5     \n",
       " 0.00193528276314131⋅x  - 0.00279317600199501⋅x  - 0.00096923753055128⋅x  + 0.\n",
       "\n",
       "                 4                       3                     2              \n",
       "141493891581525⋅x  + 0.0432639792616021⋅x  + 6.54012037706316⋅x  - 12.16244066\n",
       "\n",
       "                         \n",
       "75846⋅x + 27.286578294022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtenemos la opción seleccionada\n",
    "case = dropdown.value\n",
    "\n",
    "coeffs = []\n",
    "if case == 1:\n",
    "    \n",
    "    while True:\n",
    "        degree = int(input('Grado del polinomio: '))\n",
    "        if degree > 0:\n",
    "            break\n",
    "    A = Matrix(degree+1, degree+1, lambda i, j: nsum( lambda k: (puntos_x[int(k)])**(i+j), [0, len(puntos_x)-1]) )\n",
    "\n",
    "    B = Matrix(degree+1, 1, lambda i, j: nsum(lambda k: puntos_y[int(k)]*(puntos_x[int(k)])**i , [0, len(puntos_y)-1]) )\n",
    "    #Declaramos un arreglo para los coeficientes\n",
    "    \n",
    "    for i in range(0, degree+1):\n",
    "        coeffs.append(Symbol('a'+str(i)))\n",
    "\n",
    "    #Resolvemos el sistema de ecuaciones\n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    #Construimos el polinomio\n",
    "    pol = c.args[0].args[0]\n",
    "    for i in range(1, degree+1):\n",
    "        pol += (c.args[0].args[i])*x**i\n",
    "        \n",
    "elif case == 2:\n",
    "    \n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (puntos_x[int(k)])**(i+j), [0, len(puntos_x) -1]))\n",
    "    B = Matrix(2, 1, lambda i, j: nsum( lambda k: ln(puntos_y[int(k)]) * (puntos_x[int(k)])**i, [0, len(puntos_y) -1]))\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    pol = exp(c.args[0].args[0]) * exp(c.args[0].args[1]*x)\n",
    "    \n",
    "elif case == 3:\n",
    "\n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (ln(puntos_x[int(k)]))**(i+j), [0, len(puntos_x)-1]) )\n",
    "    B = Matrix(2, 1, lambda i, j: nsum(lambda k: ln(puntos_y[int(k)])*(ln(puntos_x[int(k)]))**i , [0, len(puntos_y)-1]) )\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    pol = exp(c.args[0].args[0]) * x ** c.args[0].args[1]\n",
    "\n",
    "elif case == 4:\n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (ln(puntos_x[int(k)]))**(i+j), [0, len(puntos_x)-1]) )\n",
    "    B = Matrix(2, 1, lambda i, j: nsum(lambda k: ln(puntos_x[int(k)])**i * (puntos_y[int(k)]) , [0, len(puntos_y)-1]) )\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    pol = c.args[0].args[0] + c.args[0].args[1] * log(x)\n",
    "    \n",
    "display(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
