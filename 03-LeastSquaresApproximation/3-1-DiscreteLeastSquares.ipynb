{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimos cuadrados: caso discreto\n",
    "\n",
    "Dada una nube de puntos $ \\{ (x_{1}, y_{1}), (x_{2}, y_{2}), \\ldots , (x_{m}, y_{m})  \\} \\subseteq \\mathbb{R}^{2} $  deseamos buscar una función que provea una buena aproximación en cada uno de los $m$ puntos. Para poder abordar este problema, es necesario especificar a qué nos referimos con *buena aproximación*. \n",
    "Con este propósito, introducimos la noción de norma $2$ en $\\mathbb{R}^{m}$. Dado $\\mathbf{v} = ( v_{1}, \\ldots, v_{m} ) \\in \\mathbb{R}^{m}$, tenemos que\n",
    "\n",
    "$$ || \\mathbf{v} ||_{2} = \\left( \\sum_{i=1}^{m} (v_{i})^{2}  \\right) ^{ \\frac{1}{2} }   $$ \n",
    "\n",
    "Consideremos la nube de puntos como dos vectores m-dimensionales: $\\mathbf{x} = (x_{1}, x_{2}, \\ldots , x_{m}) \\in \\mathbb{R}^{m}$ y $\\mathbf{y} = (y_{1}, y_{2}, \\ldots , y_{m}) \\in \\mathbb{R}^{m} $ y supongamos que buscamos un polinomio $p_{n}$ de grado menor o igual que $n$ para aproximar la nube de puntos; es decir, deseamos minimizar la distancia entre cada $y_{i}$ en la nube de puntos y los valores de $p_{n}(x_{i})$. Si denotamos por $\\mathbf{p}$ el vector $m$-dimensional $( p_{n}(x_{1}), p_{n}(x_{2}), \\ldots , p_{n}(x_{m}) )$ tenemos que \n",
    "\n",
    "$$  || \\mathbf{y} - \\mathbf{p} ||_{2}   =  \\left( \\sum_{i=1}^{m} (y_{i} - p_{n}(x_{i}))^{2}  \\right) ^{ \\frac{1}{2} }  $$ \n",
    "\n",
    "Minimizar esta expresión es equivalente a minimizar\n",
    "\n",
    "$$  || \\mathbf{y} - \\mathbf{p} ||_{2}^{2}   =  \\sum_{i=1}^{m} (y_{i} - p_{n}(x_{i}))^{2}     $$\n",
    "\n",
    "Si escribimos $p_{n}(x)$ como $ \\sum_{i=0}^{n} a_{i} x^{i} $ notamos que esta expresión depende únicamente de los coeficientes del polinomio. De forma que si se desea obtener un mínimo, se debe asegurar la derivada parcial de esta expresión respecto a cada coeficiente $a_{i}$, $i = 0, 1, 2, \\ldots , n$ sea igual a $0$. Al realizar la derivación parcial e igualar a $0$, obtenemos el siguiente sistema de $n+1$ ecuaciones para los $n+1$ coeficientes:\n",
    "\n",
    "$$ \\begin{array}{rcr} a_{0}\\langle \\mathbf{1}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{1}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{1}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{1}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{1} \\rangle \\\\ \n",
    "a_{0}\\langle \\mathbf{x}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{x}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{x}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{x}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{x} \\rangle \\\\  \\vdots \\\\ \n",
    "a_{0}\\langle \\mathbf{x}^{n}, \\mathbf{1} \\rangle + a_{1}\\langle \\mathbf{x}^{n}, \\mathbf{x} \\rangle + a_{2}\\langle \\mathbf{x}^{n}, \\mathbf{x}^{2} \\rangle + \\ldots + a_{n}\\langle \\mathbf{x}^{n}, \\mathbf{x}^{n} \\rangle\n",
    "& = & \\langle \\mathbf{y}, \\mathbf{x}^{n} \\rangle  \\end{array} $$\n",
    "\n",
    "donde denotamos por $\\mathbf{x} ^{i}$ el vector $(x_{1}^{i}, x_{2}^{i}, \\ldots , x_{m}^{i})$ y $\\langle \\mathbf{v}, \\mathbf{w} \\rangle = \\sum_{i=1}^{m} v_{i} w_{i}  $ es el producto interno en $\\mathbb{R} ^{m}$. Para el enfoque polinomial, resolvemos este sistema de ecuaciones para buscar los coeficientes.\n",
    "Si se sospecha que los datos tienen una relación exponencial, minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - a_{0} e^{a_{1} x_{i}})^{2}     $$\n",
    "\n",
    "linealizando la expresión como \n",
    "\n",
    "$$ \\sum_{i=1}^{m} (\\ln(y_{i}) - ( \\ln(a_{0}) + a_{1} x_{i} ))^{2}  $$\n",
    "\n",
    "Si sospechamos que los datos tienen una relación potencial, en su lugar minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - a_{0} x^{a_{1}})^{2} $$ \n",
    "\n",
    "linealizando como \n",
    "\n",
    "$$ \\sum_{i=1}^{m} (\\ln(y_{i}) - ( \\ln(a_{0}) + a_{1} \\ln( x_{i}) ))^{2}  $$\n",
    "\n",
    "Por último, si los datos tienen una relación logarítmica, minimizamos\n",
    "\n",
    "$$ \\sum_{i=1}^{m} (y_{i} - ( a_{0} + a_{1} \\ln( x_{i}) ))^{2}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x\n",
    "from mpmath import nsum\n",
    "\n",
    "from IPython.display import display, Latex\n",
    "from ipywidgets import interact, widgets, Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sympy.interactive import printing;\n",
    "printing.init_printing(use_latex=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de puntos a ingresar: 2\n"
     ]
    }
   ],
   "source": [
    "n = int(input('Cantidad de puntos a ingresar: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 1\n",
      "y0 = 1\n",
      "x1 = 2\n",
      "y1 = 2\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$ \\mathbf{x} = \\left [ 1.0, \\quad 2.0\\right ]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$ \\mathbf{y} = \\left [ 1.0, \\quad 2.0\\right ]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "puntos_x = []\n",
    "puntos_y = []\n",
    "for i in range(n):\n",
    "    puntos_x.append(float(input('x{:d} = '.format(i))))\n",
    "    puntos_y.append(float(input('y{:d} = '.format(i))))\n",
    "\n",
    "minval = maxval = puntos_x[0]\n",
    "for value in puntos_x:\n",
    "    if value < minval:\n",
    "        minval = value\n",
    "    if value > maxval:\n",
    "        maxval = value \n",
    "    \n",
    "display(Latex('$$ \\mathbf{x} = '+latex(puntos_x)+'$$'))\n",
    "display(Latex('$$ \\mathbf{y} = '+latex(puntos_y)+'$$'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c561eda8ef4c77a3c1b6aa0adcb830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Tipo de regresión: ', options={'Polinomial': 1, 'Exponencial': 2, 'Potencial': 3, 'Logar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case = 1\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options = {'Polinomial' : 1, 'Exponencial' : 2, 'Potencial' : 3, 'Logarítmica' : 4},\n",
    "    value = 1,\n",
    "    description = 'Tipo de regresión: '\n",
    ");\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grado del polinomio: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$$a_{2} x^{2} + 2.0 a_{2} + a_{3} x^{3} + 6.0 a_{3} + x \\left(- 3.0 a_{2} - 7.0 a_{3} + 1.0\\right)$$"
      ],
      "text/plain": [
       "    2                3                                      \n",
       "a₂⋅x  + 2.0⋅a₂ + a₃⋅x  + 6.0⋅a₃ + x⋅(-3.0⋅a₂ - 7.0⋅a₃ + 1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtenemos la opción seleccionada\n",
    "case = dropdown.value\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10));\n",
    "\n",
    "coeffs = []\n",
    "\n",
    "#Regresión polinomial\n",
    "if case == 1:\n",
    "    \n",
    "    while True:\n",
    "        degree = int(input('Grado del polinomio: '))\n",
    "        if degree > 0:\n",
    "            break\n",
    "    A = Matrix(degree+1, degree+1, lambda i, j: nsum( lambda k: (puntos_x[int(k)])**(i+j), [0, len(puntos_x)-1]) )\n",
    "\n",
    "    B = Matrix(degree+1, 1, lambda i, j: nsum(lambda k: puntos_y[int(k)]*(puntos_x[int(k)])**i , [0, len(puntos_y)-1]) )\n",
    "    #Declaramos un arreglo para los coeficientes\n",
    "    \n",
    "    for i in range(0, degree+1):\n",
    "        coeffs.append(Symbol('a'+str(i)))\n",
    "\n",
    "    #Resolvemos el sistema de ecuaciones\n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    #Construimos el polinomio\n",
    "    pol = c.args[0].args[0]\n",
    "    for i in range(1, degree+1):\n",
    "        pol += (c.args[0].args[i])*x**i\n",
    "        \n",
    "#Regresión exponencial      \n",
    "elif case == 2:\n",
    "    \n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (puntos_x[int(k)])**(i+j), [0, len(puntos_x) -1]))\n",
    "    B = Matrix(2, 1, lambda i, j: nsum( lambda k: ln(puntos_y[int(k)]) * (puntos_x[int(k)])**i, [0, len(puntos_y) -1]))\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    pol = exp(c.args[0].args[0]) * E**(c.args[0].args[1]*x)\n",
    "    \n",
    "#Regresión potencial    \n",
    "elif case == 3:\n",
    "\n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (ln(puntos_x[int(k)]))**(i+j), [0, len(puntos_x)-1]) )\n",
    "    B = Matrix(2, 1, lambda i, j: nsum(lambda k: ln(puntos_y[int(k)])*(ln(puntos_x[int(k)]))**i , [0, len(puntos_y)-1]) )\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "    \n",
    "    pol = exp(c.args[0].args[0]) * x ** c.args[0].args[1]\n",
    "\n",
    "#Regresión logarítmica    \n",
    "elif case == 4:\n",
    "    A = Matrix(2, 2, lambda i, j: nsum( lambda k: (ln(puntos_x[int(k)]))**(i+j), [0, len(puntos_x)-1]) )\n",
    "    B = Matrix(2, 1, lambda i, j: nsum(lambda k: ln(puntos_x[int(k)])**i * (puntos_y[int(k)]) , [0, len(puntos_y)-1]) )\n",
    "    \n",
    "    coeffs = [Symbol('a0'), Symbol('a1')]\n",
    "    \n",
    "    display(A)\n",
    "    display(B)\n",
    "    \n",
    "    c = linsolve((A, B), coeffs)\n",
    "\n",
    "    \n",
    "    pol = c.args[0].args[0] + c.args[0].args[1] * log(x)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "xpoints = np.array(puntos_x);\n",
    "ypoints = np.array(puntos_y);\n",
    "\n",
    "lambdaf = lambdify(x, pol);\n",
    "xv = np.linspace(minval , maxval  , 50);\n",
    "ax.plot(xv, lambdaf(xv), color='green');\n",
    "ax.scatter(xpoints, ypoints, color='blue', marker='o');\n",
    "plt.show();    \n",
    "\n",
    "display(pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "[B&F] Burden, R. L., & Faires, D. J. & Burden, A. M. (2017). Aproximación por mínimos cuadrados discretos. En *Análisis numérico*, 10a ed. Cengage Learning.\n",
    "\n",
    "\n",
    "[S&M] Süli, E., & Mayers, D. F. (2002). Solutions of systems of linear equations. En *An introduction to numerical analysis*. Cambridge: Cambridge University Press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
